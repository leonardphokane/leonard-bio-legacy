# 🕵️‍♂️ Responsible AI Inspector

**Short case studies on how artificial intelligence systems can go wrong — and how we can design them better.**

Created as part of a Responsible AI assignment for the PLP program, this open-source repo shares ethics in action through storytelling, inspection, and design correction.

---

## 🔍 Case Files

### 1️⃣ The Hiring Bot with Hidden Bias
- 📌 Rejects applicants with career gaps — disproportionately impacting women.
- ⚠️ Flawed historical data and opaque selection criteria.
- ✅ Fix: Add fairness constraints + human review for flagged cases.

### 2️⃣ The School Proctoring AI with Tunnel Vision
- 📌 Flags cheating based on eye movement in remote exams.
- ⚠️ Neurodivergent students penalized unfairly.
- ✅ Fix: Include accessibility accommodations and human-in-the-loop validation.

---

## ✍️ Narrative Write-ups

Each audit is written like a mini blog post — accessible, thoughtful, and themed around digital accountability.  
Full write-ups live in [`CASE_NOTES.md`](CASE_NOTES.md)

---

## 🧰 Repo Structure

```plaintext
├── README.md              # This manifesto
├── CASE_NOTES.md          # Inspector-style blog entries
├── LICENSE                # MIT license
├── .gitignore             # Repo hygiene rules
├── assets/                # Visual elements (badges, screenshots)

🌱 Use This Format
Got your own audit story? Fork this repo, drop in your notebook and blog-style narrative — then submit a pull request.

Bias is rarely accidental. Accountability shouldn't be optional.

👤 Author
Leonard Phokane Ethical AI Advocate · Creative Technologist 🔗 GitHub Portfolio 🌐 Portfolio Site

📄 License
Released under MIT License — use, remix, and share responsibly.
